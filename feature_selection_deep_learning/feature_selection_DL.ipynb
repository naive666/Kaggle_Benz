{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:46.680301Z",
     "start_time": "2019-12-25T12:55:40.405023Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:48.836131Z",
     "start_time": "2019-12-25T12:55:47.738893Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:49.503176Z",
     "start_time": "2019-12-25T12:55:49.497191Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:50.401792Z",
     "start_time": "2019-12-25T12:55:50.393814Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:51.200659Z",
     "start_time": "2019-12-25T12:55:51.112892Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:51.853940Z",
     "start_time": "2019-12-25T12:55:51.850272Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:52.951854Z",
     "start_time": "2019-12-25T12:55:52.681566Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('E:/kaggle/Benz/data/train.csv/train.csv')\n",
    "test = pd.read_csv('E:/kaggle/Benz/data/test.csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:53.913556Z",
     "start_time": "2019-12-25T12:55:53.865684Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_test = pd.concat((train, test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:56.625228Z",
     "start_time": "2019-12-25T12:55:56.619249Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyTransfomer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        \"\"\"\n",
    "        X : Dataframe, which needed to be transformed\n",
    "        \"\"\"\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        new_X = X.copy()\n",
    "        for column_name in new_X.columns:\n",
    "            if new_X[column_name].dtype == 'object':\n",
    "                dummy = pd.get_dummies(new_X[column_name])\n",
    "                new_X = pd.concat([new_X, dummy], axis = 1)\n",
    "                new_X.drop(column_name, axis = 1, inplace = True)\n",
    "        return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:55:58.258423Z",
     "start_time": "2019-12-25T12:55:57.497458Z"
    }
   },
   "outputs": [],
   "source": [
    "dummytransfer = DummyTransfomer()\n",
    "dummytransfer.fit(train_test)\n",
    "new_train_test = dummytransfer.transform(train_test.drop('y', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:00.451086Z",
     "start_time": "2019-12-25T12:56:00.425127Z"
    }
   },
   "outputs": [],
   "source": [
    "new_train_test.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:02.543371Z",
     "start_time": "2019-12-25T12:56:02.539382Z"
    }
   },
   "outputs": [],
   "source": [
    "def keras_r2(y_true, y_predict):\n",
    "    SS_res = K.sum(K.square(y_true - y_predict))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return SS_res/(SS_tot + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:03.536520Z",
     "start_time": "2019-12-25T12:56:03.530051Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    train_shape = train.shape\n",
    "    m = train_shape[0]\n",
    "    n = train_shape[1]\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(m / 4, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(m / 8, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(m / 16, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = Adam(), metrics = [keras_r2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:05.695575Z",
     "start_time": "2019-12-25T12:56:05.689593Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:06.940622Z",
     "start_time": "2019-12-25T12:56:06.936604Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:09.102722Z",
     "start_time": "2019-12-25T12:56:09.097736Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = new_train_test.iloc[:4209, :]\n",
    "X_test = new_train_test.iloc[4209:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:10.173351Z",
     "start_time": "2019-12-25T12:56:10.169362Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:11.054095Z",
     "start_time": "2019-12-25T12:56:11.049133Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn = my_model, nb_epoch = 300, batch_size = 300, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T12:56:11.885894Z",
     "start_time": "2019-12-25T12:56:11.881904Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 4, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:02:44.670217Z",
     "start_time": "2019-12-25T13:02:44.666227Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:04:57.390955Z",
     "start_time": "2019-12-25T13:04:57.385970Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = [#callbacks.EarlyStopping(monitor = 'keras_r2', patience = 10, mode = 'max', verbose = 1), \n",
    "            callbacks.ModelCheckpoint('ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5', save_best_only=True),\n",
    "            callbacks.TensorBoard(log_dir = 'my_model', histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:21:32.532639Z",
     "start_time": "2019-12-25T13:21:32.512692Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(X_train, y_train, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:23:19.447109Z",
     "start_time": "2019-12-25T13:23:16.430487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3156 samples, validate on 1053 samples\n",
      "3156/3156 [==============================] - 3s 813us/sample - loss: 10249.0138 - keras_r2: 65.4234 - val_loss: 10175.4203 - val_keras_r2: 63.7689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12a0bf97d48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(new_X_train.values, new_y_train.values, callbacks = callback, validation_data = (new_X_test.values, new_y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:05:33.536147Z",
     "start_time": "2019-12-25T13:04:59.036678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3156 samples, validate on 1053 samples\n",
      "Epoch 1/300\n",
      "3156/3156 [==============================] - 2s 666us/sample - loss: 10241.4902 - keras_r2: 65.5165 - val_loss: 10183.9074 - val_keras_r2: 69.6250\n",
      "Epoch 2/300\n",
      "3156/3156 [==============================] - 1s 169us/sample - loss: 10162.6534 - keras_r2: 64.3545 - val_loss: 10131.9777 - val_keras_r2: 69.2371\n",
      "Epoch 3/300\n",
      "3156/3156 [==============================] - 1s 177us/sample - loss: 10093.1761 - keras_r2: 65.3924 - val_loss: 10069.4940 - val_keras_r2: 68.7880\n",
      "Epoch 4/300\n",
      "3156/3156 [==============================] - 1s 177us/sample - loss: 10023.2473 - keras_r2: 63.8227 - val_loss: 9997.6439 - val_keras_r2: 68.2960\n",
      "Epoch 5/300\n",
      "3156/3156 [==============================] - 1s 206us/sample - loss: 9942.4321 - keras_r2: 62.9346 - val_loss: 9930.1100 - val_keras_r2: 67.8482\n",
      "Epoch 6/300\n",
      "3156/3156 [==============================] - 1s 189us/sample - loss: 9860.6882 - keras_r2: 63.7811 - val_loss: 9812.3673 - val_keras_r2: 67.0537\n",
      "Epoch 7/300\n",
      "3156/3156 [==============================] - 1s 179us/sample - loss: 9755.1066 - keras_r2: 61.9812 - val_loss: 9701.3749 - val_keras_r2: 66.2972\n",
      "Epoch 8/300\n",
      "3156/3156 [==============================] - 1s 193us/sample - loss: 9630.4268 - keras_r2: 62.4955 - val_loss: 9610.8595 - val_keras_r2: 65.6810\n",
      "Epoch 9/300\n",
      "3156/3156 [==============================] - 1s 179us/sample - loss: 9460.6330 - keras_r2: 60.9043 - val_loss: 9453.4549 - val_keras_r2: 64.6124\n",
      "Epoch 10/300\n",
      "3156/3156 [==============================] - 1s 180us/sample - loss: 9282.9089 - keras_r2: 60.0539 - val_loss: 9202.6265 - val_keras_r2: 62.9303\n",
      "Epoch 11/300\n",
      "3156/3156 [==============================] - 1s 185us/sample - loss: 9083.0238 - keras_r2: 59.3211 - val_loss: 8974.6756 - val_keras_r2: 61.3631\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1053/1053 [==============================] - 0s 116us/sample\n",
      "Train on 3157 samples, validate on 1052 samples\n",
      "Epoch 1/300\n",
      "3157/3157 [==============================] - 2s 564us/sample - loss: 10213.3895 - keras_r2: 67.3011 - val_loss: 10325.9074 - val_keras_r2: 58.5150\n",
      "Epoch 2/300\n",
      "3157/3157 [==============================] - 0s 154us/sample - loss: 10137.6361 - keras_r2: 66.8399 - val_loss: 10213.8158 - val_keras_r2: 57.8738\n",
      "Epoch 3/300\n",
      "3157/3157 [==============================] - 1s 165us/sample - loss: 10068.3684 - keras_r2: 67.7289 - val_loss: 10134.6140 - val_keras_r2: 57.4255\n",
      "Epoch 4/300\n",
      "3157/3157 [==============================] - 0s 157us/sample - loss: 9993.0439 - keras_r2: 65.6234 - val_loss: 10030.5011 - val_keras_r2: 56.8434\n",
      "Epoch 5/300\n",
      "3157/3157 [==============================] - 1s 164us/sample - loss: 9931.9791 - keras_r2: 66.2920 - val_loss: 9931.8550 - val_keras_r2: 56.2946\n",
      "Epoch 6/300\n",
      "3157/3157 [==============================] - 1s 163us/sample - loss: 9829.3482 - keras_r2: 65.1530 - val_loss: 9831.9462 - val_keras_r2: 55.7428\n",
      "Epoch 7/300\n",
      "3157/3157 [==============================] - 1s 173us/sample - loss: 9731.8341 - keras_r2: 64.7241 - val_loss: 9671.0157 - val_keras_r2: 54.8401\n",
      "Epoch 8/300\n",
      "3157/3157 [==============================] - 0s 150us/sample - loss: 9595.8784 - keras_r2: 63.5162 - val_loss: 9524.2017 - val_keras_r2: 54.0176\n",
      "Epoch 9/300\n",
      "3157/3157 [==============================] - 0s 150us/sample - loss: 9452.5075 - keras_r2: 62.6597 - val_loss: 9406.0125 - val_keras_r2: 53.3514\n",
      "Epoch 10/300\n",
      "3157/3157 [==============================] - 0s 158us/sample - loss: 9276.1066 - keras_r2: 61.4059 - val_loss: 9264.8258 - val_keras_r2: 52.5596\n",
      "Epoch 11/300\n",
      "3157/3157 [==============================] - 1s 168us/sample - loss: 9068.6873 - keras_r2: 60.2614 - val_loss: 9104.1665 - val_keras_r2: 51.6619\n",
      "Epoch 12/300\n",
      "3157/3157 [==============================] - 1s 171us/sample - loss: 8839.2394 - keras_r2: 58.5359 - val_loss: 8820.7828 - val_keras_r2: 50.0584\n",
      "Epoch 13/300\n",
      "3157/3157 [==============================] - 1s 174us/sample - loss: 8584.6588 - keras_r2: 57.2927 - val_loss: 8521.9458 - val_keras_r2: 48.3503\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1052/1052 [==============================] - 0s 111us/sample\n",
      "Train on 3157 samples, validate on 1052 samples\n",
      "Epoch 1/300\n",
      "3157/3157 [==============================] - 2s 585us/sample - loss: 10261.5587 - keras_r2: 64.0526 - val_loss: 10173.6520 - val_keras_r2: 70.9904\n",
      "Epoch 2/300\n",
      "3157/3157 [==============================] - 1s 160us/sample - loss: 10170.7553 - keras_r2: 64.7620 - val_loss: 10076.9351 - val_keras_r2: 70.3344\n",
      "Epoch 3/300\n",
      "3157/3157 [==============================] - 1s 163us/sample - loss: 10100.7744 - keras_r2: 65.2349 - val_loss: 9970.3125 - val_keras_r2: 69.6124\n",
      "Epoch 4/300\n",
      "3157/3157 [==============================] - 1s 161us/sample - loss: 10034.2279 - keras_r2: 63.3137 - val_loss: 9910.9009 - val_keras_r2: 69.2229\n",
      "Epoch 5/300\n",
      "3157/3157 [==============================] - 1s 184us/sample - loss: 9956.4735 - keras_r2: 62.1739 - val_loss: 9771.1398 - val_keras_r2: 68.2691\n",
      "Epoch 6/300\n",
      "3157/3157 [==============================] - 1s 173us/sample - loss: 9865.4012 - keras_r2: 61.1503 - val_loss: 9686.6343 - val_keras_r2: 67.6927\n",
      "Epoch 7/300\n",
      "3157/3157 [==============================] - 1s 163us/sample - loss: 9757.8778 - keras_r2: 61.2284 - val_loss: 9610.6036 - val_keras_r2: 67.1663\n",
      "Epoch 8/300\n",
      "3157/3157 [==============================] - 1s 171us/sample - loss: 9629.2687 - keras_r2: 60.8194 - val_loss: 9494.5617 - val_keras_r2: 66.3799\n",
      "Epoch 9/300\n",
      "3157/3157 [==============================] - 1s 166us/sample - loss: 9469.0358 - keras_r2: 58.7432 - val_loss: 9344.1707 - val_keras_r2: 65.3520\n",
      "Epoch 10/300\n",
      "3157/3157 [==============================] - 0s 155us/sample - loss: 9296.0195 - keras_r2: 57.9208 - val_loss: 9156.1954 - val_keras_r2: 64.0391\n",
      "Epoch 11/300\n",
      "3157/3157 [==============================] - 1s 175us/sample - loss: 9102.5770 - keras_r2: 56.7619 - val_loss: 9020.6474 - val_keras_r2: 63.0922\n",
      "Epoch 12/300\n",
      "3157/3157 [==============================] - 0s 158us/sample - loss: 8854.7213 - keras_r2: 56.5452 - val_loss: 8877.2919 - val_keras_r2: 62.0918\n",
      "Epoch 13/300\n",
      "3157/3157 [==============================] - 1s 178us/sample - loss: 8580.7647 - keras_r2: 53.9504 - val_loss: 8502.5850 - val_keras_r2: 59.4870\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1052/1052 [==============================] - 0s 114us/sample\n",
      "Train on 3157 samples, validate on 1052 samples\n",
      "Epoch 1/300\n",
      "3157/3157 [==============================] - 2s 554us/sample - loss: 10276.0138 - keras_r2: 64.0669 - val_loss: 10088.6617 - val_keras_r2: 71.2402\n",
      "Epoch 2/300\n",
      "3157/3157 [==============================] - 1s 159us/sample - loss: 10193.9153 - keras_r2: 63.6969 - val_loss: 10015.8303 - val_keras_r2: 70.6973\n",
      "Epoch 3/300\n",
      "3157/3157 [==============================] - 1s 165us/sample - loss: 10128.8783 - keras_r2: 63.1877 - val_loss: 9965.0805 - val_keras_r2: 70.3128\n",
      "Epoch 4/300\n",
      "3157/3157 [==============================] - 1s 161us/sample - loss: 10062.6699 - keras_r2: 63.6267 - val_loss: 9908.1238 - val_keras_r2: 69.8960\n",
      "Epoch 5/300\n",
      "3157/3157 [==============================] - 1s 168us/sample - loss: 9979.8210 - keras_r2: 62.2669 - val_loss: 9875.5412 - val_keras_r2: 69.6619\n",
      "Epoch 6/300\n",
      "3157/3157 [==============================] - 1s 162us/sample - loss: 9890.0117 - keras_r2: 61.6408 - val_loss: 9720.9246 - val_keras_r2: 68.5795\n",
      "Epoch 7/300\n",
      "3157/3157 [==============================] - 0s 157us/sample - loss: 9783.5662 - keras_r2: 61.7723 - val_loss: 9632.0146 - val_keras_r2: 67.9601\n",
      "Epoch 8/300\n",
      "3157/3157 [==============================] - 1s 162us/sample - loss: 9660.6679 - keras_r2: 60.1822 - val_loss: 9559.0242 - val_keras_r2: 67.4478\n",
      "Epoch 9/300\n",
      "3157/3157 [==============================] - 1s 164us/sample - loss: 9506.2866 - keras_r2: 59.2000 - val_loss: 9370.7548 - val_keras_r2: 66.1203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300\n",
      "3157/3157 [==============================] - 1s 167us/sample - loss: 9325.1199 - keras_r2: 58.4748 - val_loss: 9148.3401 - val_keras_r2: 64.5589\n",
      "Epoch 11/300\n",
      "3157/3157 [==============================] - 0s 150us/sample - loss: 9106.2565 - keras_r2: 56.2967 - val_loss: 9038.0349 - val_keras_r2: 63.7690\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1052/1052 [==============================] - 0s 110us/sample\n"
     ]
    }
   ],
   "source": [
    "# r2_score_fold_list = []\n",
    "# for train_index, test_index in kf.split(X_train):\n",
    "#     estimator.fit(X_train.iloc[train_index, :].values, y_train.iloc[train_index].values, epochs = 300, callbacks = callback, validation_data = (X_train.iloc[test_index,:].values, y_train.iloc[test_index].values))\n",
    "#     prediction = estimator.predict(X_train.iloc[test_index, :])\n",
    "#     r2_evaluation = r2_score(y_train.iloc[test_index], prediction)\n",
    "#     r2_score_fold_list.append(r2_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:06:13.078321Z",
     "start_time": "2019-12-25T13:06:13.068347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-55.46741876755028,\n",
       " -45.39890199010135,\n",
       " -55.77554579787883,\n",
       " -59.15082526287438]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_fold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:23:48.415081Z",
     "start_time": "2019-12-25T13:23:48.044074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "4209/4209 [==============================] - 0s 63us/sample\n"
     ]
    }
   ],
   "source": [
    "test_prediction = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:23:50.482036Z",
     "start_time": "2019-12-25T13:23:50.477050Z"
    }
   },
   "outputs": [],
   "source": [
    "test['y'] = pd.Series(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-25T13:23:51.522309Z",
     "start_time": "2019-12-25T13:23:51.499368Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['ID', 'y']].to_csv('my_submission4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
