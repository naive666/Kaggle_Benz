{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T11:37:52.400449Z",
     "start_time": "2019-12-23T11:37:49.466509Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T11:37:53.816974Z",
     "start_time": "2019-12-23T11:37:53.537276Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('E:/kaggle/Benz/data/train.csv/train.csv')\n",
    "test = pd.read_csv('E:/kaggle/Benz/data/test.csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T11:38:03.941394Z",
     "start_time": "2019-12-23T11:38:03.937405Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T11:38:13.158927Z",
     "start_time": "2019-12-23T11:38:13.153940Z"
    }
   },
   "outputs": [],
   "source": [
    "test['y'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T11:38:22.804079Z",
     "start_time": "2019-12-23T11:38:22.723054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_test = pd.concat((train, test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T11:50:31.769958Z",
     "start_time": "2019-12-23T11:50:31.747020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X10</th>\n",
       "      <th>X100</th>\n",
       "      <th>X101</th>\n",
       "      <th>X102</th>\n",
       "      <th>X103</th>\n",
       "      <th>X104</th>\n",
       "      <th>X105</th>\n",
       "      <th>...</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0 X1  X10  X100  X101  X102  X103  X104  X105  ...  X91  X92  X93  \\\n",
       "0   0   k  v    0     0     0     0     0     0     0  ...    0    0    0   \n",
       "1   6   k  t    0     1     1     0     0     0     0  ...    0    0    0   \n",
       "2   7  az  w    0     0     1     0     0     0     0  ...    0    0    0   \n",
       "3   9  az  t    0     0     1     0     0     0     0  ...    0    0    0   \n",
       "4  13  az  v    0     0     1     0     0     0     0  ...    0    0    0   \n",
       "\n",
       "   X94  X95  X96  X97  X98  X99       y  \n",
       "0    0    0    0    0    0    0  130.81  \n",
       "1    0    0    1    0    1    0   88.53  \n",
       "2    0    0    1    0    1    0   76.26  \n",
       "3    0    0    1    0    1    0   80.62  \n",
       "4    0    0    1    0    1    0   78.02  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T11:52:59.312822Z",
     "start_time": "2019-12-23T11:52:59.298860Z"
    }
   },
   "outputs": [],
   "source": [
    "df = train_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:00:23.248905Z",
     "start_time": "2019-12-23T12:00:23.194050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X10</th>\n",
       "      <th>X100</th>\n",
       "      <th>X101</th>\n",
       "      <th>X102</th>\n",
       "      <th>X103</th>\n",
       "      <th>X104</th>\n",
       "      <th>X105</th>\n",
       "      <th>...</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4204</td>\n",
       "      <td>8410</td>\n",
       "      <td>aj</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4205</td>\n",
       "      <td>8411</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4206</td>\n",
       "      <td>8413</td>\n",
       "      <td>y</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4207</td>\n",
       "      <td>8414</td>\n",
       "      <td>ak</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4208</td>\n",
       "      <td>8416</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8418 rows Ã— 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  X0  X1  X10  X100  X101  X102  X103  X104  X105  ...  q  r  s  t  \\\n",
       "0        0   k   v    0     0     0     0     0     0     0  ...  0  0  0  0   \n",
       "1        6   k   t    0     1     1     0     0     0     0  ...  0  0  0  0   \n",
       "2        7  az   w    0     0     1     0     0     0     0  ...  0  0  0  0   \n",
       "3        9  az   t    0     0     1     0     0     0     0  ...  0  0  0  0   \n",
       "4       13  az   v    0     0     1     0     0     0     0  ...  0  0  0  0   \n",
       "...    ...  ..  ..  ...   ...   ...   ...   ...   ...   ...  ... .. .. .. ..   \n",
       "4204  8410  aj   h    0     1     1     0     1     0     0  ...  0  0  0  0   \n",
       "4205  8411   t  aa    0     1     1     0     1     0     0  ...  0  0  0  1   \n",
       "4206  8413   y   v    0     1     1     0     1     0     0  ...  0  0  0  0   \n",
       "4207  8414  ak   v    0     1     1     0     1     0     0  ...  0  0  0  0   \n",
       "4208  8416   t  aa    0     1     1     0     1     0     0  ...  0  0  0  1   \n",
       "\n",
       "      u  v  w  x  y  z  \n",
       "0     0  0  0  0  0  0  \n",
       "1     0  0  0  0  0  0  \n",
       "2     0  0  0  0  0  0  \n",
       "3     0  0  0  0  0  0  \n",
       "4     0  0  0  0  0  0  \n",
       "...  .. .. .. .. .. ..  \n",
       "4204  0  0  0  0  0  0  \n",
       "4205  0  0  0  0  0  0  \n",
       "4206  0  0  0  0  1  0  \n",
       "4207  0  0  0  0  0  0  \n",
       "4208  0  0  0  0  0  0  \n",
       "\n",
       "[8418 rows x 431 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = pd.get_dummies(train_test['X0'])\n",
    "pd.concat([df,dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:01:36.164416Z",
     "start_time": "2019-12-23T12:01:36.157464Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyTransfomer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        \"\"\"\n",
    "        X : Dataframe, which needed to be transformed\n",
    "        \"\"\"\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        new_X = X.copy()\n",
    "        for column_name in new_X.columns:\n",
    "            if new_X[column_name].dtype == 'object':\n",
    "                dummy = pd.get_dummies(new_X[column_name])\n",
    "                new_X = pd.concat([new_X, dummy], axis = 1)\n",
    "                new_X.drop(column_name, axis = 1, inplace = True)\n",
    "        return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:02:03.093215Z",
     "start_time": "2019-12-23T12:02:02.371351Z"
    }
   },
   "outputs": [],
   "source": [
    "dummytransfer = DummyTransfomer()\n",
    "dummytransfer.fit(train_test)\n",
    "new_train_test = dummytransfer.transform(train_test.drop('y', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:02:37.250207Z",
     "start_time": "2019-12-23T12:02:37.227238Z"
    }
   },
   "outputs": [],
   "source": [
    "new_train_test.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:33:39.974699Z",
     "start_time": "2019-12-23T12:33:39.970737Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LassoLarsCV, LassoCV, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.utils import check_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:09:10.647505Z",
     "start_time": "2019-12-23T12:09:10.643517Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:07:15.165687Z",
     "start_time": "2019-12-23T12:07:15.161697Z"
    }
   },
   "outputs": [],
   "source": [
    "X_new_train_test = new_train_test.iloc[:4209, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:03:05.080121Z",
     "start_time": "2019-12-23T12:03:05.057055Z"
    }
   },
   "outputs": [],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        X_transformed = np.hstack((X, self.estimator.predict(X).reshape(-1,1)))\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoLarsCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:52:25.103762Z",
     "start_time": "2019-12-23T12:52:25.098746Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked_pipeline = Pipeline(\n",
    "    [('LassoLarsCV', StackingEstimator(LassoLarsCV(cv = 3))),\n",
    "     ('GradientBoostingRegressor', StackingEstimator(GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth = 4, max_features = 'auto', min_samples_leaf=18, min_samples_split=14, subsample=0.7))),\n",
    "     ('LassoLarsCV2', LassoLarsCV())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:52:38.141472Z",
     "start_time": "2019-12-23T12:52:27.381725Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.597e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.597e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.165e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.766e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.766e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.588e-02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.547e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.514e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.474e-02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.447e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.453e-02, previous alpha=1.443e-02, with an active set of 18 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.893e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.946e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.946e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.105e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.531e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.457e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.412e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=1.418e-02, previous alpha=1.357e-02, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.688e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.820e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.407e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.338e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.019e-02, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.019e-02, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=8.406e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=8.406e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.805e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.346e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.035e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.032e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.717e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.126e-03, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.994e-03, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.947e-03, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.670e-03, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.528e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.520e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.994e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.994e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.994e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=5.024e-03, previous alpha=4.821e-03, with an active set of 61 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.682e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.682e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.570e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.309e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.309e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.493e-02, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.219e-02, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.148e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.148e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=9.314e-03, previous alpha=9.304e-03, with an active set of 23 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.176e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.369e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.369e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.358e-03, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.191e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.147e-03, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.560e-03, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.560e-03, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.560e-03, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.435e-03, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=2.400e-03, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=2.400e-03, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=2.400e-03, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.198e-03, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.165e-03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.165e-03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.116e-03, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 117 iterations, alpha=1.974e-03, previous alpha=1.890e-03, with an active set of 116 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.004e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.285e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.923e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=5.052e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.651e-03, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.651e-03, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.885e-03, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.885e-03, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.847e-03, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.493e-03, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.335e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.070e-03, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.070e-03, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=3.053e-03, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.996e-03, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.706e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.521e-03, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.521e-03, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.517e-03, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=2.292e-03, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=2.292e-03, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 99 iterations, alpha=2.288e-03, previous alpha=2.274e-03, with an active set of 96 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.690e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.636e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.636e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.636e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=4.396e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.932e-03, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.783e-03, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.783e-03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.395e-03, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=3.113e-03, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=2.960e-03, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=2.809e-03, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.800e-03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.800e-03, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.800e-03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.759e-03, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.534e-03, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.424e-03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.424e-03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.375e-03, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.288e-03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 101 iterations, alpha=2.355e-03, previous alpha=2.288e-03, with an active set of 100 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('LassoLarsCV',\n",
       "                 StackingEstimator(estimator=LassoLarsCV(copy_X=True, cv=3,\n",
       "                                                         eps=2.220446049250313e-16,\n",
       "                                                         fit_intercept=True,\n",
       "                                                         max_iter=500,\n",
       "                                                         max_n_alphas=1000,\n",
       "                                                         n_jobs=None,\n",
       "                                                         normalize=True,\n",
       "                                                         positive=False,\n",
       "                                                         precompute='auto',\n",
       "                                                         verbose=False))),\n",
       "                ('GradientBoostingRegressor',\n",
       "                 StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                                       crit...\n",
       "                                                                       n_iter_no_change=None,\n",
       "                                                                       presort='auto',\n",
       "                                                                       random_state=None,\n",
       "                                                                       subsample=0.7,\n",
       "                                                                       tol=0.0001,\n",
       "                                                                       validation_fraction=0.1,\n",
       "                                                                       verbose=0,\n",
       "                                                                       warm_start=False))),\n",
       "                ('LassoLarsCV2',\n",
       "                 LassoLarsCV(copy_X=True, cv='warn', eps=2.220446049250313e-16,\n",
       "                             fit_intercept=True, max_iter=500,\n",
       "                             max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "                             positive=False, precompute='auto',\n",
       "                             verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_pipeline.fit(X_new_train_test, train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:52:40.116980Z",
     "start_time": "2019-12-23T12:52:40.007274Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked_prediction = stacked_pipeline.predict(X_new_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:52:43.257434Z",
     "start_time": "2019-12-23T12:52:43.253444Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation = r2_score(train['y'], stacked_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:52:44.314888Z",
     "start_time": "2019-12-23T12:52:44.309901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809655067518915"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:46:06.906011Z",
     "start_time": "2019-12-23T12:46:06.901023Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = new_train_test.iloc[4209:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:52:51.074893Z",
     "start_time": "2019-12-23T12:52:50.965188Z"
    }
   },
   "outputs": [],
   "source": [
    "test_stacked_predict = stacked_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:53:06.232877Z",
     "start_time": "2019-12-23T12:53:06.228912Z"
    }
   },
   "outputs": [],
   "source": [
    "test['y'] = pd.Series(test_stacked_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T12:53:07.951268Z",
     "start_time": "2019-12-23T12:53:07.925337Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['ID', 'y']].to_csv('my_submission3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
