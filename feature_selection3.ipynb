{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:10:24.360601Z",
     "start_time": "2019-12-22T11:10:21.079823Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:32:13.371689Z",
     "start_time": "2019-12-22T14:32:13.100416Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('E:/kaggle/Benz/data/train.csv/train.csv')\n",
    "test = pd.read_csv('E:/kaggle/Benz/data/test.csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:10:29.685940Z",
     "start_time": "2019-12-22T11:10:27.694263Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:14:16.407224Z",
     "start_time": "2019-12-22T11:14:16.401273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4209"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:13:15.826651Z",
     "start_time": "2019-12-22T11:13:15.822641Z"
    }
   },
   "outputs": [],
   "source": [
    "test['y'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:13:18.630920Z",
     "start_time": "2019-12-22T11:13:18.614966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>az</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0 X1  X2 X3 X4 X5 X6 X8  X10  ...  X376  X377  X378  X379  X380  X382  \\\n",
       "0   1  az  v   n  f  d  t  a  w    0  ...     0     0     1     0     0     0   \n",
       "1   2   t  b  ai  a  d  b  g  y    0  ...     0     1     0     0     0     0   \n",
       "2   3  az  v  as  f  d  a  j  j    0  ...     0     0     1     0     0     0   \n",
       "3   4  az  l   n  f  d  z  l  n    0  ...     0     0     1     0     0     0   \n",
       "4   5   w  s  as  c  d  y  i  m    0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   X383  X384  X385  y  \n",
       "0     0     0     0 -1  \n",
       "1     0     0     0 -1  \n",
       "2     0     0     0 -1  \n",
       "3     0     0     0 -1  \n",
       "4     0     0     0 -1  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:16:52.794336Z",
     "start_time": "2019-12-22T11:16:52.736492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_test = pd.concat((train, test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:16:54.843940Z",
     "start_time": "2019-12-22T11:16:54.819004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X10</th>\n",
       "      <th>X100</th>\n",
       "      <th>X101</th>\n",
       "      <th>X102</th>\n",
       "      <th>X103</th>\n",
       "      <th>X104</th>\n",
       "      <th>X105</th>\n",
       "      <th>...</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4204</td>\n",
       "      <td>8410</td>\n",
       "      <td>aj</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4205</td>\n",
       "      <td>8411</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4206</td>\n",
       "      <td>8413</td>\n",
       "      <td>y</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4207</td>\n",
       "      <td>8414</td>\n",
       "      <td>ak</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4208</td>\n",
       "      <td>8416</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8418 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  X0  X1  X10  X100  X101  X102  X103  X104  X105  ...  X91  X92  \\\n",
       "0        0   k   v    0     0     0     0     0     0     0  ...    0    0   \n",
       "1        6   k   t    0     1     1     0     0     0     0  ...    0    0   \n",
       "2        7  az   w    0     0     1     0     0     0     0  ...    0    0   \n",
       "3        9  az   t    0     0     1     0     0     0     0  ...    0    0   \n",
       "4       13  az   v    0     0     1     0     0     0     0  ...    0    0   \n",
       "...    ...  ..  ..  ...   ...   ...   ...   ...   ...   ...  ...  ...  ...   \n",
       "4204  8410  aj   h    0     1     1     0     1     0     0  ...    0    0   \n",
       "4205  8411   t  aa    0     1     1     0     1     0     0  ...    0    0   \n",
       "4206  8413   y   v    0     1     1     0     1     0     0  ...    0    0   \n",
       "4207  8414  ak   v    0     1     1     0     1     0     0  ...    0    0   \n",
       "4208  8416   t  aa    0     1     1     0     1     0     0  ...    0    0   \n",
       "\n",
       "      X93  X94  X95  X96  X97  X98  X99       y  \n",
       "0       0    0    0    0    0    0    0  130.81  \n",
       "1       0    0    0    1    0    1    0   88.53  \n",
       "2       0    0    0    1    0    1    0   76.26  \n",
       "3       0    0    0    1    0    1    0   80.62  \n",
       "4       0    0    0    1    0    1    0   78.02  \n",
       "...   ...  ...  ...  ...  ...  ...  ...     ...  \n",
       "4204    0    0    0    1    0    1    0   -1.00  \n",
       "4205    0    0    0    1    0    1    0   -1.00  \n",
       "4206    0    0    0    1    0    1    0   -1.00  \n",
       "4207    0    0    0    1    0    1    0   -1.00  \n",
       "4208    0    0    0    0    0    1    0   -1.00  \n",
       "\n",
       "[8418 rows x 378 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder to transfer categorical features to numerical ones\n",
    "- Here I write a new class in case that I maybe put this operation to Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:11:01.620569Z",
     "start_time": "2019-12-22T11:11:01.614584Z"
    }
   },
   "outputs": [],
   "source": [
    "class LabelEncoderTransfomer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        \"\"\"\n",
    "        X : Dataframe, which needed to be transformed\n",
    "        \"\"\"\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        for column_name in X.columns:\n",
    "            if X[column_name].dtype == 'object' and (column_name != 'y'):\n",
    "                le = LabelEncoder()\n",
    "                standardscaler = StandardScaler()\n",
    "                X[column_name] = le.fit_transform(X[column_name])\n",
    "                X[column_name] = pd.Series(standardscaler.fit_transform(X[column_name].values.reshape(-1,1)).reshape(-1))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:18:13.204684Z",
     "start_time": "2019-12-22T11:18:13.198701Z"
    }
   },
   "outputs": [],
   "source": [
    "label_transform = LabelEncoderTransfomer()\n",
    "label_transform.fit(train_test)\n",
    "new_train_test = label_transform.transform(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:20:04.027745Z",
     "start_time": "2019-12-22T11:20:00.982849Z"
    }
   },
   "outputs": [],
   "source": [
    "new_train_test.to_csv('new_train_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here We Try Some Demension-Reduction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:20:22.213199Z",
     "start_time": "2019-12-22T11:20:22.209238Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD, FastICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:21:13.253746Z",
     "start_time": "2019-12-22T11:21:13.099160Z"
    }
   },
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components = 12)\n",
    "tsvd_train_test = tsvd.fit_transform(new_train_test.drop('y', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:21:15.458827Z",
     "start_time": "2019-12-22T11:21:15.454807Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tsvd_train_test = pd.DataFrame(tsvd_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:21:20.879437Z",
     "start_time": "2019-12-22T11:21:20.863481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>3.504640</td>\n",
       "      <td>0.448356</td>\n",
       "      <td>2.540893</td>\n",
       "      <td>-1.092674</td>\n",
       "      <td>-1.035575</td>\n",
       "      <td>0.549141</td>\n",
       "      <td>-0.276696</td>\n",
       "      <td>0.033261</td>\n",
       "      <td>-0.431983</td>\n",
       "      <td>1.064780</td>\n",
       "      <td>-0.146923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.006371</td>\n",
       "      <td>5.370430</td>\n",
       "      <td>-0.443093</td>\n",
       "      <td>-0.313193</td>\n",
       "      <td>-1.554533</td>\n",
       "      <td>-0.099392</td>\n",
       "      <td>0.195953</td>\n",
       "      <td>-0.887304</td>\n",
       "      <td>-0.286928</td>\n",
       "      <td>-0.971999</td>\n",
       "      <td>1.422245</td>\n",
       "      <td>-0.277710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.005382</td>\n",
       "      <td>4.362660</td>\n",
       "      <td>-1.510002</td>\n",
       "      <td>2.528752</td>\n",
       "      <td>-1.989034</td>\n",
       "      <td>1.989749</td>\n",
       "      <td>1.151217</td>\n",
       "      <td>-1.736666</td>\n",
       "      <td>3.776413</td>\n",
       "      <td>0.687438</td>\n",
       "      <td>0.233074</td>\n",
       "      <td>-0.544641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.004889</td>\n",
       "      <td>3.850197</td>\n",
       "      <td>-1.369152</td>\n",
       "      <td>1.399486</td>\n",
       "      <td>-1.985495</td>\n",
       "      <td>3.359381</td>\n",
       "      <td>1.009941</td>\n",
       "      <td>-2.251635</td>\n",
       "      <td>1.865824</td>\n",
       "      <td>-0.167175</td>\n",
       "      <td>-1.194269</td>\n",
       "      <td>-0.580179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.004808</td>\n",
       "      <td>4.206323</td>\n",
       "      <td>-1.500189</td>\n",
       "      <td>1.181247</td>\n",
       "      <td>-2.244818</td>\n",
       "      <td>3.689727</td>\n",
       "      <td>0.508670</td>\n",
       "      <td>-1.479261</td>\n",
       "      <td>2.326718</td>\n",
       "      <td>1.797962</td>\n",
       "      <td>-1.171942</td>\n",
       "      <td>-0.452691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8413</td>\n",
       "      <td>8410.002106</td>\n",
       "      <td>-1.825387</td>\n",
       "      <td>-3.113885</td>\n",
       "      <td>-0.422523</td>\n",
       "      <td>0.556627</td>\n",
       "      <td>0.545228</td>\n",
       "      <td>0.563886</td>\n",
       "      <td>1.108247</td>\n",
       "      <td>0.343997</td>\n",
       "      <td>1.140874</td>\n",
       "      <td>0.215526</td>\n",
       "      <td>-0.067482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8414</td>\n",
       "      <td>8411.002024</td>\n",
       "      <td>-2.042546</td>\n",
       "      <td>1.864371</td>\n",
       "      <td>1.016534</td>\n",
       "      <td>-1.416667</td>\n",
       "      <td>-0.170655</td>\n",
       "      <td>2.106344</td>\n",
       "      <td>-1.303946</td>\n",
       "      <td>-0.785766</td>\n",
       "      <td>0.618829</td>\n",
       "      <td>-0.319423</td>\n",
       "      <td>0.081116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8415</td>\n",
       "      <td>8413.001446</td>\n",
       "      <td>-2.652414</td>\n",
       "      <td>-1.482261</td>\n",
       "      <td>-1.255950</td>\n",
       "      <td>1.223946</td>\n",
       "      <td>2.059268</td>\n",
       "      <td>1.719786</td>\n",
       "      <td>-0.713328</td>\n",
       "      <td>-1.179701</td>\n",
       "      <td>0.468298</td>\n",
       "      <td>-0.402466</td>\n",
       "      <td>0.490422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8416</td>\n",
       "      <td>8414.002613</td>\n",
       "      <td>-1.219981</td>\n",
       "      <td>-2.514477</td>\n",
       "      <td>1.285928</td>\n",
       "      <td>0.878828</td>\n",
       "      <td>0.120052</td>\n",
       "      <td>0.691112</td>\n",
       "      <td>-0.458032</td>\n",
       "      <td>0.239292</td>\n",
       "      <td>-0.499400</td>\n",
       "      <td>2.087022</td>\n",
       "      <td>-0.360091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8417</td>\n",
       "      <td>8416.001754</td>\n",
       "      <td>-2.290257</td>\n",
       "      <td>1.857524</td>\n",
       "      <td>-1.201152</td>\n",
       "      <td>-1.961266</td>\n",
       "      <td>-2.419958</td>\n",
       "      <td>0.956039</td>\n",
       "      <td>-0.143955</td>\n",
       "      <td>0.562573</td>\n",
       "      <td>1.023584</td>\n",
       "      <td>1.235304</td>\n",
       "      <td>-0.192562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8418 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "0        0.004187  3.504640  0.448356  2.540893 -1.092674 -1.035575  0.549141   \n",
       "1        6.006371  5.370430 -0.443093 -0.313193 -1.554533 -0.099392  0.195953   \n",
       "2        7.005382  4.362660 -1.510002  2.528752 -1.989034  1.989749  1.151217   \n",
       "3        9.004889  3.850197 -1.369152  1.399486 -1.985495  3.359381  1.009941   \n",
       "4       13.004808  4.206323 -1.500189  1.181247 -2.244818  3.689727  0.508670   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "8413  8410.002106 -1.825387 -3.113885 -0.422523  0.556627  0.545228  0.563886   \n",
       "8414  8411.002024 -2.042546  1.864371  1.016534 -1.416667 -0.170655  2.106344   \n",
       "8415  8413.001446 -2.652414 -1.482261 -1.255950  1.223946  2.059268  1.719786   \n",
       "8416  8414.002613 -1.219981 -2.514477  1.285928  0.878828  0.120052  0.691112   \n",
       "8417  8416.001754 -2.290257  1.857524 -1.201152 -1.961266 -2.419958  0.956039   \n",
       "\n",
       "             7         8         9        10        11  \n",
       "0    -0.276696  0.033261 -0.431983  1.064780 -0.146923  \n",
       "1    -0.887304 -0.286928 -0.971999  1.422245 -0.277710  \n",
       "2    -1.736666  3.776413  0.687438  0.233074 -0.544641  \n",
       "3    -2.251635  1.865824 -0.167175 -1.194269 -0.580179  \n",
       "4    -1.479261  2.326718  1.797962 -1.171942 -0.452691  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "8413  1.108247  0.343997  1.140874  0.215526 -0.067482  \n",
       "8414 -1.303946 -0.785766  0.618829 -0.319423  0.081116  \n",
       "8415 -0.713328 -1.179701  0.468298 -0.402466  0.490422  \n",
       "8416 -0.458032  0.239292 -0.499400  2.087022 -0.360091  \n",
       "8417 -0.143955  0.562573  1.023584  1.235304 -0.192562  \n",
       "\n",
       "[8418 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tsvd_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:24:58.559066Z",
     "start_time": "2019-12-22T11:24:58.367609Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 12)\n",
    "pca_train_test = pca.fit_transform(new_train_test.drop('y', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:24:59.667230Z",
     "start_time": "2019-12-22T11:24:59.663270Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pca_train_test = pd.DataFrame(pca_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:25:08.448369Z",
     "start_time": "2019-12-22T11:25:08.431414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-4208.499477</td>\n",
       "      <td>0.532109</td>\n",
       "      <td>2.217775</td>\n",
       "      <td>-1.805524</td>\n",
       "      <td>0.337378</td>\n",
       "      <td>1.345693</td>\n",
       "      <td>-0.196151</td>\n",
       "      <td>0.298937</td>\n",
       "      <td>-0.457754</td>\n",
       "      <td>0.689447</td>\n",
       "      <td>0.153159</td>\n",
       "      <td>-0.410301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-4202.499309</td>\n",
       "      <td>-0.510979</td>\n",
       "      <td>-0.504593</td>\n",
       "      <td>-1.376521</td>\n",
       "      <td>-0.445898</td>\n",
       "      <td>0.100867</td>\n",
       "      <td>-0.893468</td>\n",
       "      <td>-0.037290</td>\n",
       "      <td>-0.993333</td>\n",
       "      <td>1.228246</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>-0.568656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-4201.499344</td>\n",
       "      <td>-1.434948</td>\n",
       "      <td>1.982969</td>\n",
       "      <td>-2.964873</td>\n",
       "      <td>2.070493</td>\n",
       "      <td>-0.266574</td>\n",
       "      <td>-1.879875</td>\n",
       "      <td>3.252355</td>\n",
       "      <td>1.685636</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>-0.672356</td>\n",
       "      <td>0.168887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-4199.499351</td>\n",
       "      <td>-1.227089</td>\n",
       "      <td>0.778288</td>\n",
       "      <td>-3.043404</td>\n",
       "      <td>3.023373</td>\n",
       "      <td>-1.268789</td>\n",
       "      <td>-2.476929</td>\n",
       "      <td>1.767112</td>\n",
       "      <td>0.318589</td>\n",
       "      <td>-0.564533</td>\n",
       "      <td>-1.010763</td>\n",
       "      <td>1.056174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-4195.499833</td>\n",
       "      <td>-1.383928</td>\n",
       "      <td>0.551971</td>\n",
       "      <td>-3.189972</td>\n",
       "      <td>2.900028</td>\n",
       "      <td>-1.816926</td>\n",
       "      <td>-1.660214</td>\n",
       "      <td>1.783393</td>\n",
       "      <td>2.307281</td>\n",
       "      <td>-0.895818</td>\n",
       "      <td>-0.589956</td>\n",
       "      <td>-0.503373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8413</td>\n",
       "      <td>4201.499435</td>\n",
       "      <td>-3.133986</td>\n",
       "      <td>-0.342656</td>\n",
       "      <td>0.587272</td>\n",
       "      <td>0.362604</td>\n",
       "      <td>-0.007551</td>\n",
       "      <td>0.791541</td>\n",
       "      <td>-0.396450</td>\n",
       "      <td>1.352632</td>\n",
       "      <td>0.619742</td>\n",
       "      <td>-0.268626</td>\n",
       "      <td>0.683773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8414</td>\n",
       "      <td>4202.499391</td>\n",
       "      <td>1.865696</td>\n",
       "      <td>0.855904</td>\n",
       "      <td>-1.377175</td>\n",
       "      <td>-0.361784</td>\n",
       "      <td>1.247382</td>\n",
       "      <td>-1.870090</td>\n",
       "      <td>-1.188893</td>\n",
       "      <td>0.508367</td>\n",
       "      <td>-0.125714</td>\n",
       "      <td>-0.021292</td>\n",
       "      <td>-0.106625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8415</td>\n",
       "      <td>4204.499529</td>\n",
       "      <td>-1.407667</td>\n",
       "      <td>-1.213379</td>\n",
       "      <td>0.937728</td>\n",
       "      <td>2.106543</td>\n",
       "      <td>-0.214216</td>\n",
       "      <td>-1.349363</td>\n",
       "      <td>-1.649294</td>\n",
       "      <td>0.302366</td>\n",
       "      <td>-0.106015</td>\n",
       "      <td>0.205222</td>\n",
       "      <td>0.737280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8416</td>\n",
       "      <td>4205.499353</td>\n",
       "      <td>-2.620561</td>\n",
       "      <td>1.490403</td>\n",
       "      <td>0.905006</td>\n",
       "      <td>-0.271381</td>\n",
       "      <td>0.084113</td>\n",
       "      <td>-0.758810</td>\n",
       "      <td>-0.169294</td>\n",
       "      <td>-0.196169</td>\n",
       "      <td>2.492780</td>\n",
       "      <td>-0.261001</td>\n",
       "      <td>0.341145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8417</td>\n",
       "      <td>4207.499468</td>\n",
       "      <td>1.859267</td>\n",
       "      <td>-1.308263</td>\n",
       "      <td>-1.230020</td>\n",
       "      <td>-2.313017</td>\n",
       "      <td>1.970791</td>\n",
       "      <td>-0.263712</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>1.191332</td>\n",
       "      <td>1.129651</td>\n",
       "      <td>0.055231</td>\n",
       "      <td>-0.411734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8418 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "0    -4208.499477  0.532109  2.217775 -1.805524  0.337378  1.345693 -0.196151   \n",
       "1    -4202.499309 -0.510979 -0.504593 -1.376521 -0.445898  0.100867 -0.893468   \n",
       "2    -4201.499344 -1.434948  1.982969 -2.964873  2.070493 -0.266574 -1.879875   \n",
       "3    -4199.499351 -1.227089  0.778288 -3.043404  3.023373 -1.268789 -2.476929   \n",
       "4    -4195.499833 -1.383928  0.551971 -3.189972  2.900028 -1.816926 -1.660214   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "8413  4201.499435 -3.133986 -0.342656  0.587272  0.362604 -0.007551  0.791541   \n",
       "8414  4202.499391  1.865696  0.855904 -1.377175 -0.361784  1.247382 -1.870090   \n",
       "8415  4204.499529 -1.407667 -1.213379  0.937728  2.106543 -0.214216 -1.349363   \n",
       "8416  4205.499353 -2.620561  1.490403  0.905006 -0.271381  0.084113 -0.758810   \n",
       "8417  4207.499468  1.859267 -1.308263 -1.230020 -2.313017  1.970791 -0.263712   \n",
       "\n",
       "             7         8         9        10        11  \n",
       "0     0.298937 -0.457754  0.689447  0.153159 -0.410301  \n",
       "1    -0.037290 -0.993333  1.228246  0.056109 -0.568656  \n",
       "2     3.252355  1.685636  0.848694 -0.672356  0.168887  \n",
       "3     1.767112  0.318589 -0.564533 -1.010763  1.056174  \n",
       "4     1.783393  2.307281 -0.895818 -0.589956 -0.503373  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "8413 -0.396450  1.352632  0.619742 -0.268626  0.683773  \n",
       "8414 -1.188893  0.508367 -0.125714 -0.021292 -0.106625  \n",
       "8415 -1.649294  0.302366 -0.106015  0.205222  0.737280  \n",
       "8416 -0.169294 -0.196169  2.492780 -0.261001  0.341145  \n",
       "8417  0.163000  1.191332  1.129651  0.055231 -0.411734  \n",
       "\n",
       "[8418 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:26:50.362804Z",
     "start_time": "2019-12-22T11:26:49.567930Z"
    }
   },
   "outputs": [],
   "source": [
    "fast_ica = FastICA(n_components = 12)\n",
    "fast_ica_train_test = fast_ica.fit_transform(new_train_test.drop('y',axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:27:01.892128Z",
     "start_time": "2019-12-22T11:27:01.888138Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fast_ica = pd.DataFrame(fast_ica_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:27:09.583037Z",
     "start_time": "2019-12-22T11:27:09.567107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>-0.019460</td>\n",
       "      <td>0.007316</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>-0.007725</td>\n",
       "      <td>0.019330</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>-0.008493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>-0.006691</td>\n",
       "      <td>0.019987</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>-0.000954</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>-0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>-0.009886</td>\n",
       "      <td>-0.008736</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>-0.047304</td>\n",
       "      <td>-0.007116</td>\n",
       "      <td>0.018602</td>\n",
       "      <td>-0.009920</td>\n",
       "      <td>-0.007538</td>\n",
       "      <td>-0.001868</td>\n",
       "      <td>-0.008228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>-0.001771</td>\n",
       "      <td>-0.002306</td>\n",
       "      <td>-0.010362</td>\n",
       "      <td>-0.046511</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.020364</td>\n",
       "      <td>-0.009750</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>-0.013588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>-0.050076</td>\n",
       "      <td>-0.002897</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>-0.013328</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8413</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>-0.006024</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>-0.019406</td>\n",
       "      <td>-0.017623</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>-0.016362</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8414</td>\n",
       "      <td>-0.009227</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>-0.005056</td>\n",
       "      <td>-0.006340</td>\n",
       "      <td>-0.009161</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-0.021775</td>\n",
       "      <td>-0.017749</td>\n",
       "      <td>-0.007416</td>\n",
       "      <td>-0.006929</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>-0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8415</td>\n",
       "      <td>-0.011514</td>\n",
       "      <td>-0.007044</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>-0.018206</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>-0.016885</td>\n",
       "      <td>-0.018461</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>-0.008793</td>\n",
       "      <td>-0.007707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8416</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.011504</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>-0.004782</td>\n",
       "      <td>-0.018632</td>\n",
       "      <td>-0.020061</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.011258</td>\n",
       "      <td>-0.016233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8417</td>\n",
       "      <td>-0.005765</td>\n",
       "      <td>-0.001843</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0.017353</td>\n",
       "      <td>0.008537</td>\n",
       "      <td>-0.016607</td>\n",
       "      <td>-0.020215</td>\n",
       "      <td>-0.002276</td>\n",
       "      <td>-0.021043</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8418 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.005359  0.001447 -0.008220 -0.019460  0.007316 -0.001310 -0.007725   \n",
       "1     0.007390  0.004519  0.005224  0.003056  0.007611  0.002938 -0.006691   \n",
       "2     0.008008  0.003004 -0.009886 -0.008736  0.018228 -0.047304 -0.007116   \n",
       "3     0.004792  0.005980 -0.001771 -0.002306 -0.010362 -0.046511  0.000152   \n",
       "4    -0.001363  0.003588 -0.001049 -0.001889  0.002614 -0.050076 -0.002897   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8413  0.006165 -0.006024  0.003843  0.000720  0.001750 -0.000519  0.005160   \n",
       "8414 -0.009227 -0.000324 -0.005056 -0.006340 -0.009161  0.000139 -0.021775   \n",
       "8415 -0.011514 -0.007044  0.007584  0.005345 -0.018206 -0.002579 -0.001985   \n",
       "8416  0.012613 -0.000411 -0.011504  0.004420  0.009686  0.006707 -0.004782   \n",
       "8417 -0.005765 -0.001843  0.006896 -0.000652  0.017353  0.008537 -0.016607   \n",
       "\n",
       "             7         8         9        10        11  \n",
       "0     0.019330 -0.001171 -0.003421  0.007916 -0.008493  \n",
       "1     0.019987 -0.006135 -0.000954  0.009616 -0.012737  \n",
       "2     0.018602 -0.009920 -0.007538 -0.001868 -0.008228  \n",
       "3     0.020364 -0.009750 -0.002591  0.003020 -0.013588  \n",
       "4     0.020431 -0.013328  0.007369  0.005006  0.009682  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "8413 -0.019406 -0.017623 -0.001167 -0.016362  0.008488  \n",
       "8414 -0.017749 -0.007416 -0.006929  0.013491 -0.002757  \n",
       "8415 -0.016885 -0.018461  0.008569 -0.008793 -0.007707  \n",
       "8416 -0.018632 -0.020061 -0.000259 -0.011258 -0.016233  \n",
       "8417 -0.020215 -0.002276 -0.021043  0.010806  0.005003  \n",
       "\n",
       "[8418 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fast_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append decomposition components to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:41:41.254125Z",
     "start_time": "2019-12-22T11:41:41.223206Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(12):\n",
    "    df['tsvd_' + str(i)] = df_tsvd_train_test.iloc[:, i]\n",
    "    df['pca_' + str(i)] = df_pca_train_test.iloc[:, i]\n",
    "    df['fast_ica_' + str(i)] = df_fast_ica.iloc[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:41:53.107784Z",
     "start_time": "2019-12-22T11:41:53.072908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsvd_0</th>\n",
       "      <th>pca_0</th>\n",
       "      <th>fast_ica_0</th>\n",
       "      <th>tsvd_1</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>fast_ica_1</th>\n",
       "      <th>tsvd_2</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>fast_ica_2</th>\n",
       "      <th>tsvd_3</th>\n",
       "      <th>...</th>\n",
       "      <th>fast_ica_8</th>\n",
       "      <th>tsvd_9</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>fast_ica_9</th>\n",
       "      <th>tsvd_10</th>\n",
       "      <th>pca_10</th>\n",
       "      <th>fast_ica_10</th>\n",
       "      <th>tsvd_11</th>\n",
       "      <th>pca_11</th>\n",
       "      <th>fast_ica_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>-4208.499477</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>3.504640</td>\n",
       "      <td>0.532109</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.448356</td>\n",
       "      <td>2.217775</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>2.540893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>-0.431983</td>\n",
       "      <td>0.689447</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>1.064780</td>\n",
       "      <td>0.153159</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>-0.146923</td>\n",
       "      <td>-0.410301</td>\n",
       "      <td>-0.008493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.006371</td>\n",
       "      <td>-4202.499309</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>5.370430</td>\n",
       "      <td>-0.510979</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>-0.443093</td>\n",
       "      <td>-0.504593</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>-0.313193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>-0.971999</td>\n",
       "      <td>1.228246</td>\n",
       "      <td>-0.000954</td>\n",
       "      <td>1.422245</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>-0.277710</td>\n",
       "      <td>-0.568656</td>\n",
       "      <td>-0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.005382</td>\n",
       "      <td>-4201.499344</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>4.362660</td>\n",
       "      <td>-1.434948</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>-1.510002</td>\n",
       "      <td>1.982969</td>\n",
       "      <td>-0.009886</td>\n",
       "      <td>2.528752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009920</td>\n",
       "      <td>0.687438</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>-0.007538</td>\n",
       "      <td>0.233074</td>\n",
       "      <td>-0.672356</td>\n",
       "      <td>-0.001868</td>\n",
       "      <td>-0.544641</td>\n",
       "      <td>0.168887</td>\n",
       "      <td>-0.008228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.004889</td>\n",
       "      <td>-4199.499351</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>3.850197</td>\n",
       "      <td>-1.227089</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>-1.369152</td>\n",
       "      <td>0.778288</td>\n",
       "      <td>-0.001771</td>\n",
       "      <td>1.399486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009750</td>\n",
       "      <td>-0.167175</td>\n",
       "      <td>-0.564533</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>-1.194269</td>\n",
       "      <td>-1.010763</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>-0.580179</td>\n",
       "      <td>1.056174</td>\n",
       "      <td>-0.013588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.004808</td>\n",
       "      <td>-4195.499833</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>4.206323</td>\n",
       "      <td>-1.383928</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>-1.500189</td>\n",
       "      <td>0.551971</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>1.181247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013328</td>\n",
       "      <td>1.797962</td>\n",
       "      <td>-0.895818</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>-1.171942</td>\n",
       "      <td>-0.589956</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>-0.452691</td>\n",
       "      <td>-0.503373</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8413</td>\n",
       "      <td>8410.002106</td>\n",
       "      <td>4201.499435</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>-1.825387</td>\n",
       "      <td>-3.133986</td>\n",
       "      <td>-0.006024</td>\n",
       "      <td>-3.113885</td>\n",
       "      <td>-0.342656</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>-0.422523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017623</td>\n",
       "      <td>1.140874</td>\n",
       "      <td>0.619742</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>0.215526</td>\n",
       "      <td>-0.268626</td>\n",
       "      <td>-0.016362</td>\n",
       "      <td>-0.067482</td>\n",
       "      <td>0.683773</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8414</td>\n",
       "      <td>8411.002024</td>\n",
       "      <td>4202.499391</td>\n",
       "      <td>-0.009227</td>\n",
       "      <td>-2.042546</td>\n",
       "      <td>1.865696</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>1.864371</td>\n",
       "      <td>0.855904</td>\n",
       "      <td>-0.005056</td>\n",
       "      <td>1.016534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007416</td>\n",
       "      <td>0.618829</td>\n",
       "      <td>-0.125714</td>\n",
       "      <td>-0.006929</td>\n",
       "      <td>-0.319423</td>\n",
       "      <td>-0.021292</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>-0.106625</td>\n",
       "      <td>-0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8415</td>\n",
       "      <td>8413.001446</td>\n",
       "      <td>4204.499529</td>\n",
       "      <td>-0.011514</td>\n",
       "      <td>-2.652414</td>\n",
       "      <td>-1.407667</td>\n",
       "      <td>-0.007044</td>\n",
       "      <td>-1.482261</td>\n",
       "      <td>-1.213379</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>-1.255950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018461</td>\n",
       "      <td>0.468298</td>\n",
       "      <td>-0.106015</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>-0.402466</td>\n",
       "      <td>0.205222</td>\n",
       "      <td>-0.008793</td>\n",
       "      <td>0.490422</td>\n",
       "      <td>0.737280</td>\n",
       "      <td>-0.007707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8416</td>\n",
       "      <td>8414.002613</td>\n",
       "      <td>4205.499353</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>-1.219981</td>\n",
       "      <td>-2.620561</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-2.514477</td>\n",
       "      <td>1.490403</td>\n",
       "      <td>-0.011504</td>\n",
       "      <td>1.285928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020061</td>\n",
       "      <td>-0.499400</td>\n",
       "      <td>2.492780</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>2.087022</td>\n",
       "      <td>-0.261001</td>\n",
       "      <td>-0.011258</td>\n",
       "      <td>-0.360091</td>\n",
       "      <td>0.341145</td>\n",
       "      <td>-0.016233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8417</td>\n",
       "      <td>8416.001754</td>\n",
       "      <td>4207.499468</td>\n",
       "      <td>-0.005765</td>\n",
       "      <td>-2.290257</td>\n",
       "      <td>1.859267</td>\n",
       "      <td>-0.001843</td>\n",
       "      <td>1.857524</td>\n",
       "      <td>-1.308263</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>-1.201152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002276</td>\n",
       "      <td>1.023584</td>\n",
       "      <td>1.129651</td>\n",
       "      <td>-0.021043</td>\n",
       "      <td>1.235304</td>\n",
       "      <td>0.055231</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>-0.192562</td>\n",
       "      <td>-0.411734</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8418 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tsvd_0        pca_0  fast_ica_0    tsvd_1     pca_1  fast_ica_1  \\\n",
       "0        0.004187 -4208.499477    0.005359  3.504640  0.532109    0.001447   \n",
       "1        6.006371 -4202.499309    0.007390  5.370430 -0.510979    0.004519   \n",
       "2        7.005382 -4201.499344    0.008008  4.362660 -1.434948    0.003004   \n",
       "3        9.004889 -4199.499351    0.004792  3.850197 -1.227089    0.005980   \n",
       "4       13.004808 -4195.499833   -0.001363  4.206323 -1.383928    0.003588   \n",
       "...           ...          ...         ...       ...       ...         ...   \n",
       "8413  8410.002106  4201.499435    0.006165 -1.825387 -3.133986   -0.006024   \n",
       "8414  8411.002024  4202.499391   -0.009227 -2.042546  1.865696   -0.000324   \n",
       "8415  8413.001446  4204.499529   -0.011514 -2.652414 -1.407667   -0.007044   \n",
       "8416  8414.002613  4205.499353    0.012613 -1.219981 -2.620561   -0.000411   \n",
       "8417  8416.001754  4207.499468   -0.005765 -2.290257  1.859267   -0.001843   \n",
       "\n",
       "        tsvd_2     pca_2  fast_ica_2    tsvd_3  ...  fast_ica_8    tsvd_9  \\\n",
       "0     0.448356  2.217775   -0.008220  2.540893  ...   -0.001171 -0.431983   \n",
       "1    -0.443093 -0.504593    0.005224 -0.313193  ...   -0.006135 -0.971999   \n",
       "2    -1.510002  1.982969   -0.009886  2.528752  ...   -0.009920  0.687438   \n",
       "3    -1.369152  0.778288   -0.001771  1.399486  ...   -0.009750 -0.167175   \n",
       "4    -1.500189  0.551971   -0.001049  1.181247  ...   -0.013328  1.797962   \n",
       "...        ...       ...         ...       ...  ...         ...       ...   \n",
       "8413 -3.113885 -0.342656    0.003843 -0.422523  ...   -0.017623  1.140874   \n",
       "8414  1.864371  0.855904   -0.005056  1.016534  ...   -0.007416  0.618829   \n",
       "8415 -1.482261 -1.213379    0.007584 -1.255950  ...   -0.018461  0.468298   \n",
       "8416 -2.514477  1.490403   -0.011504  1.285928  ...   -0.020061 -0.499400   \n",
       "8417  1.857524 -1.308263    0.006896 -1.201152  ...   -0.002276  1.023584   \n",
       "\n",
       "         pca_9  fast_ica_9   tsvd_10    pca_10  fast_ica_10   tsvd_11  \\\n",
       "0     0.689447   -0.003421  1.064780  0.153159     0.007916 -0.146923   \n",
       "1     1.228246   -0.000954  1.422245  0.056109     0.009616 -0.277710   \n",
       "2     0.848694   -0.007538  0.233074 -0.672356    -0.001868 -0.544641   \n",
       "3    -0.564533   -0.002591 -1.194269 -1.010763     0.003020 -0.580179   \n",
       "4    -0.895818    0.007369 -1.171942 -0.589956     0.005006 -0.452691   \n",
       "...        ...         ...       ...       ...          ...       ...   \n",
       "8413  0.619742   -0.001167  0.215526 -0.268626    -0.016362 -0.067482   \n",
       "8414 -0.125714   -0.006929 -0.319423 -0.021292     0.013491  0.081116   \n",
       "8415 -0.106015    0.008569 -0.402466  0.205222    -0.008793  0.490422   \n",
       "8416  2.492780   -0.000259  2.087022 -0.261001    -0.011258 -0.360091   \n",
       "8417  1.129651   -0.021043  1.235304  0.055231     0.010806 -0.192562   \n",
       "\n",
       "        pca_11  fast_ica_11  \n",
       "0    -0.410301    -0.008493  \n",
       "1    -0.568656    -0.012737  \n",
       "2     0.168887    -0.008228  \n",
       "3     1.056174    -0.013588  \n",
       "4    -0.503373     0.009682  \n",
       "...        ...          ...  \n",
       "8413  0.683773     0.008488  \n",
       "8414 -0.106625    -0.002757  \n",
       "8415  0.737280    -0.007707  \n",
       "8416  0.341145    -0.016233  \n",
       "8417 -0.411734     0.005003  \n",
       "\n",
       "[8418 rows x 36 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we get the data for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data for stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:55:19.535067Z",
     "start_time": "2019-12-22T11:55:19.488165Z"
    }
   },
   "outputs": [],
   "source": [
    "label_transform.fit(train.drop('y', axis=1))\n",
    "X_train_stacked = label_transform.transform(train.drop('y', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:41:34.497439Z",
     "start_time": "2019-12-22T12:41:34.483028Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_stacked = X_train_stacked.drop('ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T11:56:25.157294Z",
     "start_time": "2019-12-22T11:56:25.153305Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_stacked = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T13:01:38.464888Z",
     "start_time": "2019-12-22T13:01:38.429013Z"
    }
   },
   "outputs": [],
   "source": [
    "label_transform.fit(test)\n",
    "test_stacked = label_transform.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T13:02:11.808198Z",
     "start_time": "2019-12-22T13:02:11.796231Z"
    }
   },
   "outputs": [],
   "source": [
    "test_stacked.drop('ID', axis = 1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:28:01.685719Z",
     "start_time": "2019-12-22T14:28:01.673753Z"
    }
   },
   "outputs": [],
   "source": [
    "test_stacked.drop('y', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:00:13.003641Z",
     "start_time": "2019-12-22T12:00:12.999651Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_xgb = df.iloc[:4209, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:02:28.006634Z",
     "start_time": "2019-12-22T12:02:28.003670Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_xgb = train['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:20:27.690457Z",
     "start_time": "2019-12-22T12:20:27.257894Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:20:56.359610Z",
     "start_time": "2019-12-22T12:20:56.355649Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_trees': 520, \n",
    "    'eta': 0.0045,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.93,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': y_train_xgb.mean(), # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:23:53.967903Z",
     "start_time": "2019-12-22T12:23:47.694701Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_xgb, y_train_xgb)\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round = 1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:26:15.165865Z",
     "start_time": "2019-12-22T12:26:15.156891Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_predict = model.predict(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:26:24.343806Z",
     "start_time": "2019-12-22T12:26:24.339817Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:27:03.700717Z",
     "start_time": "2019-12-22T12:27:03.695760Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_evaluation = r2_score(y_train_xgb, xgb_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:27:13.914586Z",
     "start_time": "2019-12-22T12:27:13.908027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5987383574444116"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:28:22.565934Z",
     "start_time": "2019-12-22T12:28:22.349513Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LassoLarsCV, LassoCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.utils import check_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:28:26.057975Z",
     "start_time": "2019-12-22T12:28:26.051965Z"
    }
   },
   "outputs": [],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        X_transformed = np.hstack((X, self.estimator.predict(X).reshape(-1,1)))\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:41:54.938055Z",
     "start_time": "2019-12-22T12:41:44.503553Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=6, max_features = 'auto', min_samples_leaf=18, min_samples_split=14, subsample=0.7)\n",
    "stackingestimator = StackingEstimator(estimator)\n",
    "stackingestimator.fit(X_train_stacked, y_train_stacked)\n",
    "X_transformed = stackingestimator.transform(X_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:47:39.179288Z",
     "start_time": "2019-12-22T12:47:39.174302Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked_pipeline = Pipeline(\n",
    "    [('LassoLarsCV', StackingEstimator(LassoLarsCV(cv = 5))),\n",
    "     ('GradientBoostingRegressor', StackingEstimator(GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=6, max_features = 'auto', min_samples_leaf=18, min_samples_split=14, subsample=0.7))),\n",
    "     ('LassoLarsCV2', LassoLarsCV())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:47:54.158440Z",
     "start_time": "2019-12-22T12:47:42.216101Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.294e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.985e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.985e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.288e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.595e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.439e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.439e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.471e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.471e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.379e-02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.304e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.262e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.262e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.256e-02, previous alpha=1.249e-02, with an active set of 19 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.975e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.975e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.656e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.656e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.182e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.182e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.182e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.195e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.979e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.979e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.807e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.660e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.304e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.077e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 48 iterations, alpha=3.887e-03, previous alpha=3.552e-03, with an active set of 47 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.231e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.074e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.563e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.983e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.839e-02, previous alpha=1.798e-02, with an active set of 13 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.335e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.335e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.668e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.668e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.567e-02, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.402e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.297e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.297e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.297e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.116e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.039e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.841e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=8.627e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=8.625e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=8.287e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=8.245e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=8.245e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=8.333e-03, previous alpha=8.135e-03, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.206e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.206e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.603e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.603e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.692e-02, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.352e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.264e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.264e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.229e-02, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.013e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=9.664e-03, previous alpha=9.476e-03, with an active set of 23 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.682e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.682e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.341e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.341e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.330e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.282e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.211e-02, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.210e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.124e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.124e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=1.116e-02, previous alpha=1.094e-02, with an active set of 21 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.362e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.563e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.758e-03, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.675e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.086e-03, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.031e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.976e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.976e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.748e-03, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.710e-03, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.710e-03, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.710e-03, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.710e-03, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=1.470e-03, previous alpha=1.456e-03, with an active set of 83 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=3.503e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.011e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.011e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.011e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.011e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=2.916e-03, previous alpha=2.849e-03, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.283e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.371e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=3.642e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.294e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.950e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.950e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.950e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.617e-03, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.616e-03, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.372e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.138e-03, with an active set of 60 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.055e-03, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.055e-03, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.055e-03, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=2.116e-03, previous alpha=1.983e-03, with an active set of 68 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('LassoLarsCV',\n",
       "                 StackingEstimator(estimator=LassoLarsCV(copy_X=True, cv=5,\n",
       "                                                         eps=2.220446049250313e-16,\n",
       "                                                         fit_intercept=True,\n",
       "                                                         max_iter=500,\n",
       "                                                         max_n_alphas=1000,\n",
       "                                                         n_jobs=None,\n",
       "                                                         normalize=True,\n",
       "                                                         positive=False,\n",
       "                                                         precompute='auto',\n",
       "                                                         verbose=False))),\n",
       "                ('GradientBoostingRegressor',\n",
       "                 StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                                       crit...\n",
       "                                                                       n_iter_no_change=None,\n",
       "                                                                       presort='auto',\n",
       "                                                                       random_state=None,\n",
       "                                                                       subsample=0.7,\n",
       "                                                                       tol=0.0001,\n",
       "                                                                       validation_fraction=0.1,\n",
       "                                                                       verbose=0,\n",
       "                                                                       warm_start=False))),\n",
       "                ('LassoLarsCV2',\n",
       "                 LassoLarsCV(copy_X=True, cv='warn', eps=2.220446049250313e-16,\n",
       "                             fit_intercept=True, max_iter=500,\n",
       "                             max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "                             positive=False, precompute='auto',\n",
       "                             verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_pipeline.fit(X_train_stacked, y_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:26:18.653673Z",
     "start_time": "2019-12-22T14:26:18.557930Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked_prediction = stacked_pipeline.predict(X_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:26:09.107398Z",
     "start_time": "2019-12-22T14:26:09.103095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 376)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:26:23.889249Z",
     "start_time": "2019-12-22T14:26:23.884262Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked_evaluation = r2_score(y_train_stacked, stacked_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:26:26.528920Z",
     "start_time": "2019-12-22T14:26:26.524931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5950045220080578"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:57:08.054528Z",
     "start_time": "2019-12-22T12:57:08.042561Z"
    }
   },
   "outputs": [],
   "source": [
    "test_xgb = df.iloc[4209:, :]\n",
    "dtest = xgb.DMatrix(test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:57:13.440935Z",
     "start_time": "2019-12-22T12:57:13.349180Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predict_xgb = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:28:06.984032Z",
     "start_time": "2019-12-22T14:28:06.893276Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predict_stacked = stacked_pipeline.predict(test_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:32:53.073419Z",
     "start_time": "2019-12-22T14:32:53.069429Z"
    }
   },
   "outputs": [],
   "source": [
    "final_prediction = 0.75 * test_predict_xgb + 0.25 * test_predict_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:39:37.633734Z",
     "start_time": "2019-12-22T14:39:37.628745Z"
    }
   },
   "outputs": [],
   "source": [
    "test['y'] = pd.Series(test_predict_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T14:39:43.287905Z",
     "start_time": "2019-12-22T14:39:43.262933Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['ID', 'y']].to_csv('my_submission2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
